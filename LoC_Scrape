#!/usr/bin/env python3
from urllib.request import Request, urlopen
import re
import urllib.request
import random
import re
import os
import time

list_urls=[]
list_pages=[]
for i in range(30):
    url_page='https://www.loc.gov/collections/japanese-american-internment-camp-newspapers/?c=160&sp={}'.format(i)
    req = Request(url_page, headers={'User-Agent': 'Mozilla/5.0'})
	webpage = urlopen(req).read()
    web_words=str(webpage)
	list_tiffs=re.search(r"http\:\/\/www.loc.gov\/item\/sn\d+\/\d+\-\d+\-\d+\/ed\-1\/", web_words)
	non_duplicate_url=set(list_tiffs)
	list_urls.append(non_duplicate_url)
	rando=random.randint(30,45)
	time.sleep(rando)

for url in list_urls:
    url2=url+"?sp=&st=text"
    for page in list_pages:
        
    
    req = Request(url2, headers={'User-Agent': 'Mozilla/5.0'})
    webpage = urlopen(req).read()
    html_page=str(webpage)
    narrative=re.findall(r"<br/>.*</div>", html_page)
    file_all.write(respData3)
    rando=random.randint(30,45)
	time.sleep(rando)


words_url=str(list_urls)
f=open('test_url.txt','w+')
