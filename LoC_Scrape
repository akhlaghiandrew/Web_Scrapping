#!/usr/bin/env python3
from urllib.request import Request, urlopen
import re
import urllib.request
import random
import re
import os
import time

list_urls=[]
for i in range(31):
url_page='https://www.loc.gov/collections/japanese-american-internment-camp-newspapers/?c=160&sp={}'.format(i)
req = Request(url_page, headers={'User-Agent': 'Mozilla/5.0'})
webpage = urlopen(req).read()
web_words=str(webpage)
list_tiffs=re.findall(r"https\:\/\/www.loc.gov\/item\/sn\d+\/\d+\-\d+\-\d+\/ed\-\d", web_words)
list_tiffs2=re.findall(r"https\:\/\/www.loc.gov\/item\/\d+\/\d+\-\d+\-\d+\/ed\-\d", web_words)
list_tiff.extend(list_tiffs2)

for url in list_tiffs:
    for i in range(2):
        try1=url[25:]
        url2="https://www.loc.gov/resource/"+try1+"/?sp={}&st=text".format(i)
        req = Request(url2, headers={'User-Agent': 'Mozilla/5.0'})
        webpage = urlopen(req).read()
        except:
            pass
        else:
            html_page=str(webpage)
            soup = BeautifulSoup(html_page, 'html.parser')
            text=soup.find_all(id="page-fulltext-item")
            title=str(soup.title)
            title_name=title[25:30]+'.txt'
            f=open(title_name,'w+')
            text2=str(text)
            f.write(text)
            rando=random.randint(30,45)
            time.sleep(rando)
